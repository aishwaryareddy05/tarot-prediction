# -*- coding: utf-8 -*-
"""BlinkTechassignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ABbMRf5masSLnSkjfhxRFS0cXl1_fpgr
"""

pip install faker

import csv
import random
from faker import Faker

fake = Faker()

# Define categories and corresponding templates
categories = {
    "Career": [
        "The cards suggest new opportunities are coming your way.",
        "Patience is needed in your professional journey.",
        "A career change may be beneficial in the near future."
    ],
    "Love": [
        "Your heart will find what it seeks when you least expect it.",
        "The cards show a period of emotional growth ahead.",
        "An existing relationship will deepen or a new one will blossom."
    ],
    "Finance": [
        "Financial stability is on the horizon.",
        "Be cautious with investments in the coming months.",
        "Unexpected gains may come your way."
    ],
    "Health": [
        "Focus on self-care for improved wellbeing.",
        "The cards indicate a period of healing.",
        "Preventive measures will serve you well."
    ],
    "Spiritual": [
        "You're entering a phase of heightened intuition.",
        "The universe is aligning in your favor.",
        "Meditation will bring you clarity."
    ]
}

# Generate synthetic data
data = []
for _ in range(150):
    category = random.choice(list(categories.keys()))

    # Generate query based on category
    if category == "Career":
        query = fake.sentence(ext_word_list=["job", "promotion", "career", "work", "boss", "colleagues"])
    elif category == "Love":
        query = fake.sentence(ext_word_list=["love", "relationship", "partner", "marriage", "dating"])
    elif category == "Finance":
        query = fake.sentence(ext_word_list=["money", "finance", "debt", "savings", "investment"])
    elif category == "Health":
        query = fake.sentence(ext_word_list=["health", "illness", "recovery", "fitness", "wellbeing"])
    else:  # Spiritual
        query = fake.sentence(ext_word_list=["spirit", "purpose", "meaning", "destiny", "fate"])

    query = query[:-1] + "?"  # Replace . with ?
    response = random.choice(categories[category])

    data.append({
        "User Query": query,
        "Category": category,
        "Predicted Tarot Response": response
    })

# Save to CSV
with open('tarot_prediction.csv', 'w', newline='', encoding='utf-8') as csvfile:
    fieldnames = ['User Query', 'Category', 'Predicted Tarot Response']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

    writer.writeheader()
    for row in data:
        writer.writerow(row)

print("Synthetic dataset created with 150 entries."

import pandas as pd
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.preprocessing import LabelEncoder

# Download all required NLTK data
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')  # Required for WordNet lemmatization

# Initialize lemmatizer and stopwords
lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    # Lowercase
    text = text.lower()

    # Tokenize
    try:
        tokens = nltk.word_tokenize(text)
    except LookupError:
        # If punkt tokenizer isn't found, download it
        nltk.download('punkt')
        nltk.download('punkt_tab')
        tokens = nltk.word_tokenize(text)

    # Remove stopwords and non-alphabetic tokens, and lemmatize
    tokens = [lemmatizer.lemmatize(token) for token in tokens
              if token.isalpha() and token not in stop_words]

    return ' '.join(tokens)

# Load the dataset
df = pd.read_csv('tarot_prediction.csv')

# Apply preprocessing to user queries
df['Processed_Query'] = df['User Query'].apply(preprocess_text)

# Encode categories
label_encoder = LabelEncoder()
df['Category_Encoded'] = label_encoder.fit_transform(df['Category'])

# Save preprocessed data
df.to_csv('preprocessed_tarot_responses.csv', index=False)

print("Preprocessing completed. Data saved to 'preprocessed_tarot_responses.csv'")



import random
import joblib
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import pandas as pd
import nltk
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords

# Initialize NLP tools
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

# Enhanced Tarot Deck with health-related cards
tarot_cards = {
    "Major Arcana": [
        "The Fool", "The Magician", "The High Priestess",
        "The Empress", "The Emperor", "The Lovers",
        "The Chariot", "Strength", "The Hermit",
        "Wheel of Fortune", "Justice", "The Hanged Man",
        "Death", "Temperance", "The Devil",
        "The Tower", "The Star", "The Moon",
        "The Sun", "Judgement", "The World"
    ],
    "Cups": ["Ace of Cups", "Two of Cups", "Ten of Cups"],
    "Pentacles": ["Ace of Pentacles", "Four of Pentacles", "Ten of Pentacles"],
    "Health": ["Strength", "Temperance", "The Star", "The Sun", "Death"]
}

# Enhanced card meanings with health interpretations
card_meanings = {
    "Love": {
        "The Lovers": "A soulmate connection is coming within 1-2 years.",
        "Two of Cups": "A deep emotional connection will form within 6-12 months.",
        "Ten of Cups": "Marriage and family happiness is coming in 1.5-3 years."
    },
    "Career": {
        "The Magician": "Career advancement is possible within 3-6 months.",
        "Ace of Pentacles": "A new job opportunity is coming within 2-4 months.",
        "Ten of Pentacles": "Long-term career success is building."
    },
    "Health": {
        "Strength": "Your health will improve steadily with patience and self-care. Expect noticeable changes in 2-3 months.",
        "Temperance": "Balance is key to your recovery. Moderation in all things will bring health improvements in 1-2 months.",
        "The Star": "Hope and healing are coming. Significant improvement likely within 3-5 weeks.",
        "The Sun": "Vibrant health will return soon. Expect major improvements within 1 month.",
        "Death": "A transformation in your health is coming. This may involve ending unhealthy habits for renewal.",
        "The Hanged Man": "A period of waiting is needed for health improvement. Use this time for reflection and alternative healing approaches."
    }
}

def preprocess_text(text):
    tokens = nltk.word_tokenize(text.lower())
    return ' '.join([lemmatizer.lemmatize(t) for t in tokens if t.isalpha() and t not in stop_words])

def train_model():
    # Enhanced training data with health examples
    data = {
        'text': [
            'when will I find love',
            'career prospects',
            'will I get married',
            'job opportunities',
            'promotion chances',
            'when will I meet my soulmate',
            'will I get a raise',
            'financial future',
            'should I change jobs',
            'will I be rich',
            'when will I get promoted',
            'when will my health improve',
            'will I recover from illness',
            'health prognosis',
            'when will I feel better'
        ],
        'category': ['Love', 'Career', 'Love', 'Career', 'Career',
                   'Love', 'Finance', 'Finance', 'Career', 'Finance', 'Career',
                   'Health', 'Health', 'Health', 'Health']
    }
    df = pd.DataFrame(data)
    df['processed'] = df['text'].apply(preprocess_text)

    model = Pipeline([
        ('tfidf', TfidfVectorizer()),
        ('clf', LogisticRegression())
    ])
    model.fit(df['processed'], df['category'])
    return model

def get_reading(query, card_name, category):
    # Handle health questions specifically
    if "health" in query.lower() or "heal" in query.lower() or "ill" in query.lower():
        category = "Health"

    if category in card_meanings and card_name in card_meanings[category]:
        return f"""
âœ¨ {category} Reading âœ¨
Card: {card_name}
Question: {query}

Interpretation:
{card_meanings[category][card_name]}
"""
    else:
        # Find the most relevant category for the card
        for cat in card_meanings:
            if card_name in card_meanings[cat]:
                return f"""
âœ¨ {cat} Insight âœ¨
Card: {card_name}
Question: {query}

Interpretation:
{card_meanings[cat][card_name]}
"""
        return f"The {card_name} suggests important developments are coming."

def interactive_reader():
    print("ðŸ”® Accurate Tarot Reader ðŸ”®")
    query = input("\nWhat is your question? ").strip()

    # Predict category with fallback
    try:
        model = train_model()
        category = model.predict([preprocess_text(query)])[0]
    except:
        if "health" in query.lower():
            category = "Health"
        elif "promot" in query.lower() or "career" in query.lower():
            category = "Career"
        else:
            category = "Love"

    print(f"\nYour question relates to: {category}")

    # Special health card selection
    if category == "Health":
        print("\nSelect a health-related card:")
        health_cards = tarot_cards["Health"] + ["The Hanged Man", "The Hermit"]
        for i, card in enumerate(health_cards, 1):
            print(f"{i}. {card}")

        try:
            card_choice = int(input(f"Choose (1-{len(health_cards)}): ")) - 1
            card_name = health_cards[card_choice]
        except:
            card_name = random.choice(health_cards)
            print(f"Randomly selected: {card_name}")
    else:
        print("\nChoose a card type:")
        print("1. Major Arcana (Life Path)")
        print("2. Cups (Emotions/Relationships)")
        print("3. Pentacles (Career/Finances)")

        choice = input("Enter 1-3: ").strip()
        cards = tarot_cards["Major Arcana"]  # Default

        if choice == "2":
            cards = tarot_cards["Cups"]
        elif choice == "3":
            cards = tarot_cards["Pentacles"]

        print("\nSelect a card:")
        for i, card in enumerate(cards, 1):
            print(f"{i}. {card}")

        try:
            card_choice = int(input(f"Choose (1-{len(cards)}): ")) - 1
            card_name = cards[card_choice]
        except:
            card_name = random.choice(cards)
            print(f"Randomly selected: {card_name}")

    print(get_reading(query, card_name, category))

if __name__ == "__main__":
    interactive_reader()